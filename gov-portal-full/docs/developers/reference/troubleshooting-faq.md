# üîß Troubleshooting y FAQ - Nova-Cell Platform

## üìã Informaci√≥n General

**√öltima Actualizaci√≥n:** Enero 2025  
**Versi√≥n Platform:** 2.0.3  
**Canales de Soporte:** [Slack](https://banco-ai.slack.com) | [Email](mailto:ai@novasolutionsystems.com)

## üö® Problemas Comunes y Soluciones

### üî¥ Errores de Instalaci√≥n

#### Error: "Docker daemon is not running"

**S√≠ntomas:**
```bash
Cannot connect to the Docker daemon at unix:///var/run/docker.sock
```

**Soluci√≥n:**
```bash
# macOS
colima start --cpu 4 --memory 8

# Linux
sudo systemctl start docker
sudo systemctl enable docker

# Windows WSL2
wsl --shutdown
# Reiniciar Docker Desktop
```

#### Error: "Port already in use"

**S√≠ntomas:**
```bash
Error: bind: address already in use :8000
```

**Soluci√≥n:**
```bash
# Encontrar proceso usando el puerto
lsof -i :8000  # macOS/Linux
netstat -ano | findstr :8000  # Windows

# Matar proceso
kill -9 <PID>  # macOS/Linux
taskkill /PID <PID> /F  # Windows

# O cambiar puerto en configuraci√≥n
export API_PORT=8001
```

#### Error: "Insufficient memory"

**S√≠ntomas:**
```bash
ERROR: Container killed due to memory limit
```

**Soluci√≥n:**
```bash
# Aumentar l√≠mites de Docker
# Docker Desktop: Settings > Resources > Memory: 8GB m√≠nimo

# docker-compose.yml
services:
  nova-api:
    deploy:
      resources:
        limits:
          memory: 4G
        reservations:
          memory: 2G
```

### üü° Problemas de Autenticaci√≥n

#### Error: "401 Unauthorized"

**Causas comunes:**
1. Token expirado
2. Credenciales incorrectas
3. Permisos insuficientes

**Diagn√≥stico:**
```python
# Verificar token
import jwt
import json

def decode_token(token):
    try:
        # Decodificar sin verificar (solo para debug)
        decoded = jwt.decode(token, options={"verify_signature": False})
        print(json.dumps(decoded, indent=2))
        
        # Verificar expiraci√≥n
        import time
        if decoded.get('exp', 0) < time.time():
            print("‚ùå Token expirado")
        else:
            print("‚úÖ Token v√°lido")
            
    except Exception as e:
        print(f"Error decodificando token: {e}")

# Uso
decode_token("eyJ0eXAiOiJKV1Q...")
```

**Soluci√≥n:**
```python
# Renovar token autom√°ticamente
class TokenManager:
    def __init__(self, client_id, client_secret):
        self.client_id = client_id
        self.client_secret = client_secret
        self.token = None
        self.token_expiry = 0
    
    def get_valid_token(self):
        import time
        
        # Renovar si expira en menos de 5 minutos
        if time.time() > self.token_expiry - 300:
            self.refresh_token()
        
        return self.token
    
    def refresh_token(self):
        response = requests.post(
            "https://api.nova-cell.novasolutionsystems.com/auth/token",
            json={
                "client_id": self.client_id,
                "client_secret": self.client_secret,
                "grant_type": "client_credentials"
            }
        )
        
        data = response.json()
        self.token = data["access_token"]
        self.token_expiry = time.time() + data["expires_in"]
```

### üîµ Problemas con Modelos de IA

#### Error: "Rate limit exceeded"

**S√≠ntomas:**
```json
{
  "error": {
    "message": "Rate limit exceeded",
    "type": "rate_limit_error",
    "code": 429
  }
}
```

**Soluci√≥n:**
```python
# Implementar retry con exponential backoff
import time
from typing import Callable, Any

def retry_with_backoff(
    func: Callable,
    max_retries: int = 5,
    base_delay: float = 1.0
) -> Any:
    for attempt in range(max_retries):
        try:
            return func()
        except Exception as e:
            if "rate_limit" in str(e):
                delay = base_delay * (2 ** attempt)
                print(f"Rate limited. Waiting {delay}s...")
                time.sleep(delay)
            else:
                raise
    
    raise Exception("Max retries exceeded")

# Uso
result = retry_with_backoff(
    lambda: openai_client.completions.create(...)
)
```

#### Error: "Model timeout"

**S√≠ntomas:**
```
TimeoutError: Request timed out after 30 seconds
```

**Soluci√≥n:**
```python
# Configurar timeouts apropiados
import httpx

class RobustAIClient:
    def __init__(self):
        self.client = httpx.Client(
            timeout=httpx.Timeout(
                connect=5.0,      # Conexi√≥n
                read=60.0,        # Lectura (m√°s tiempo para modelos grandes)
                write=10.0,       # Escritura
                pool=5.0          # Pool de conexiones
            )
        )
    
    async def streaming_inference(self, prompt: str):
        """Usar streaming para respuestas largas"""
        async with httpx.AsyncClient() as client:
            async with client.stream(
                "POST",
                "https://api.nova-cell.novasolutionsystems.com/inference",
                json={"prompt": prompt, "stream": True}
            ) as response:
                async for chunk in response.aiter_text():
                    yield chunk
```

### üü¢ Problemas de Base de Datos

#### Error: "Connection pool exhausted"

**S√≠ntomas:**
```
psycopg2.OperationalError: FATAL: remaining connection slots are reserved
```

**Soluci√≥n:**
```python
# Configurar pool de conexiones correctamente
from sqlalchemy import create_engine
from sqlalchemy.pool import QueuePool

engine = create_engine(
    "postgresql://user:pass@localhost/db",
    poolclass=QueuePool,
    pool_size=20,           # Conexiones permanentes
    max_overflow=40,        # Conexiones adicionales temporales
    pool_pre_ping=True,     # Verificar conexi√≥n antes de usar
    pool_recycle=3600,      # Reciclar conexiones cada hora
    echo_pool=True          # Debug del pool
)

# Monitorear uso del pool
from sqlalchemy import event

@event.listens_for(engine, "connect")
def receive_connect(dbapi_conn, connection_record):
    connection_record.info['connect_time'] = time.time()

@event.listens_for(engine, "checkout")
def receive_checkout(dbapi_conn, connection_record, connection_proxy):
    age = time.time() - connection_record.info.get('connect_time', 0)
    if age > 3600:  # Conexi√≥n muy vieja
        print(f"‚ö†Ô∏è Connection age: {age}s")
```

#### Error: "Deadlock detected"

**S√≠ntomas:**
```
psycopg2.errors.DeadlockDetected: deadlock detected
```

**Soluci√≥n:**
```python
# Implementar retry logic para deadlocks
from contextlib import contextmanager
import random
import time

@contextmanager
def safe_transaction(session, max_retries=3):
    """Manejo seguro de transacciones con retry en deadlock"""
    for attempt in range(max_retries):
        try:
            yield session
            session.commit()
            break
        except Exception as e:
            session.rollback()
            
            if "deadlock" in str(e).lower():
                if attempt < max_retries - 1:
                    # Espera aleatoria para evitar colisiones
                    time.sleep(random.uniform(0.1, 0.5))
                    continue
            raise
        finally:
            session.close()

# Uso
with safe_transaction(db_session) as session:
    # Operaciones de base de datos
    pass
```

## ‚ùì Preguntas Frecuentes (FAQ)

### üè¶ General - Banca y Compliance

**P: ¬øC√≥mo aseguro que mi c√≥digo cumple con regulaciones CNBV?**

R: Utiliza nuestro checklist de compliance:
```python
# compliance_validator.py
class CNBVComplianceValidator:
    def validate_model(self, model_path: str) -> bool:
        checks = {
            "has_explainability": self.check_explainability(model_path),
            "has_audit_trail": self.check_audit_trail(model_path),
            "has_bias_testing": self.check_bias_testing(model_path),
            "has_data_lineage": self.check_data_lineage(model_path),
            "encrypted_pii": self.check_pii_encryption(model_path)
        }
        
        return all(checks.values())
```

**P: ¬øQu√© datos NO debo loggear por seguridad?**

R: Nunca loggear:
- N√∫meros de cuenta completos
- NIP/PIN
- CVV de tarjetas
- Contrase√±as
- Tokens de autenticaci√≥n
- Informaci√≥n personal identificable (PII) sin encriptar

### ü§ñ Modelos de IA

**P: ¬øCu√°l modelo debo usar para mi caso de uso?**

R: Gu√≠a de selecci√≥n:

| Caso de Uso | Modelo Recomendado | Raz√≥n |
|-------------|-------------------|--------|
| An√°lisis de documentos largos | Claude 3 Opus | Contexto de 200k tokens |
| Respuestas r√°pidas | GPT-4 Turbo | Baja latencia |
| An√°lisis financiero | GPT-4 | Mejor con n√∫meros |
| Generaci√≥n de c√≥digo | Claude 3 | C√≥digo m√°s limpio |
| B√∫squeda sem√°ntica | text-embedding-3 | Optimizado para embeddings |
| Clasificaci√≥n | Gemini Pro | Costo-efectivo |

**P: ¬øC√≥mo optimizo costos de API?**

R: Estrategias de optimizaci√≥n:
```python
# cost_optimizer.py
class AICallOptimizer:
    def optimize(self, prompt: str, context: str) -> Dict:
        # 1. Cache de respuestas frecuentes
        cache_key = hashlib.md5(prompt.encode()).hexdigest()
        if cached := self.cache.get(cache_key):
            return cached
        
        # 2. Comprimir contexto
        compressed = self.compress_context(context)
        
        # 3. Usar modelo m√°s barato primero
        if self.can_use_smaller_model(prompt):
            response = self.call_gpt35(prompt, compressed)
        else:
            response = self.call_gpt4(prompt, compressed)
        
        # 4. Cachear respuesta
        self.cache.set(cache_key, response, ttl=3600)
        
        return response
```

### üîß Desarrollo

**P: ¬øC√≥mo debuggeo inferencias de IA?**

R: Usa nuestro debugger integrado:
```python
# debug_inference.py
from nova_cell import AIDebugger

debugger = AIDebugger(verbose=True)

# Captura toda la informaci√≥n de la inferencia
with debugger.trace() as tracer:
    response = model.generate(prompt)
    
# Analiza el trace
print(tracer.get_summary())
# Output:
# - Token count: 1,523
# - Latency: 2.3s
# - Model: gpt-4
# - Temperature: 0.7
# - Cost: $0.045

# Exportar para an√°lisis
tracer.export_to_json("inference_debug.json")
```

**P: ¬øC√≥mo manejo errores de modelos de forma elegante?**

R: Implementa fallback strategy:
```python
class ModelFallbackStrategy:
    def __init__(self):
        self.models = [
            ("gpt-4", self.call_gpt4),
            ("claude-3", self.call_claude),
            ("gemini-pro", self.call_gemini),
            ("local-llama", self.call_local)
        ]
    
    async def generate_with_fallback(self, prompt: str) -> str:
        errors = []
        
        for model_name, model_func in self.models:
            try:
                return await model_func(prompt)
            except Exception as e:
                errors.append(f"{model_name}: {str(e)}")
                continue
        
        # Si todos fallan, usar respuesta predeterminada
        return self.get_default_response(prompt, errors)
```

### üöÄ Performance

**P: Mi API es muy lenta, ¬øc√≥mo la optimizo?**

R: Checklist de optimizaci√≥n:

1. **Profiling del c√≥digo:**
```python
import cProfile
import pstats

profiler = cProfile.Profile()
profiler.enable()

# Tu c√≥digo aqu√≠
result = your_slow_function()

profiler.disable()
stats = pstats.Stats(profiler).sort_stats('cumulative')
stats.print_stats(10)  # Top 10 funciones lentas
```

2. **Implementar caching:**
```python
from functools import lru_cache
from redis import Redis

redis_client = Redis()

def redis_cache(ttl=3600):
    def decorator(func):
        def wrapper(*args, **kwargs):
            key = f"{func.__name__}:{str(args)}:{str(kwargs)}"
            
            # Check cache
            if cached := redis_client.get(key):
                return json.loads(cached)
            
            # Compute and cache
            result = func(*args, **kwargs)
            redis_client.setex(key, ttl, json.dumps(result))
            
            return result
        return wrapper
    return decorator
```

3. **Usar async/await:**
```python
import asyncio
import aiohttp

async def fetch_all_data(urls):
    async with aiohttp.ClientSession() as session:
        tasks = [fetch_one(session, url) for url in urls]
        return await asyncio.gather(*tasks)
```

### üìä Monitoreo

**P: ¬øQu√© m√©tricas debo monitorear en producci√≥n?**

R: M√©tricas esenciales:

```python
# metrics_config.py
ESSENTIAL_METRICS = {
    "business": [
        "transactions_per_second",
        "approval_rate",
        "fraud_detection_rate",
        "customer_satisfaction_score"
    ],
    "technical": [
        "api_latency_p95",
        "error_rate",
        "cpu_usage",
        "memory_usage",
        "database_connections"
    ],
    "ai_specific": [
        "model_accuracy",
        "inference_latency",
        "token_usage",
        "api_costs",
        "cache_hit_rate"
    ],
    "compliance": [
        "audit_trail_completeness",
        "pii_encryption_coverage",
        "regulatory_violations",
        "model_drift"
    ]
}
```

## üõ†Ô∏è Scripts de Utilidad

### Diagn√≥stico Completo del Sistema

```bash
#!/bin/bash
# health_check.sh

echo "üîç Nova-Cell System Diagnostics"
echo "================================"

# Check services
echo "üì° Checking services..."
services=("nova-api" "postgres" "redis" "mongodb")
for service in "${services[@]}"; do
    if docker ps | grep -q $service; then
        echo "‚úÖ $service: Running"
    else
        echo "‚ùå $service: Not running"
    fi
done

# Check disk space
echo -e "\nüíæ Disk usage:"
df -h | grep -E "/$|/var|/tmp"

# Check memory
echo -e "\nüß† Memory usage:"
free -h

# Check API health
echo -e "\nüåê API Health:"
curl -s http://localhost:8000/health | jq '.'

# Check database connections
echo -e "\nüóÑÔ∏è Database connections:"
docker exec postgres psql -U nova_admin -c \
    "SELECT count(*) as connections FROM pg_stat_activity;"

# Check Redis
echo -e "\nüì¶ Redis status:"
docker exec redis redis-cli INFO server | grep uptime

# Check logs for errors
echo -e "\n‚ö†Ô∏è Recent errors (last 10):"
docker logs nova-api 2>&1 | grep ERROR | tail -10
```

### Reset de Ambiente de Desarrollo

```bash
#!/bin/bash
# reset_dev_env.sh

echo "üîÑ Resetting development environment..."

# Stop all containers
docker-compose down -v

# Clean Docker
docker system prune -af

# Clear caches
rm -rf ~/.cache/pip
rm -rf node_modules
rm -rf __pycache__
find . -type d -name "*.egg-info" -exec rm -rf {} +

# Reset databases
rm -rf data/postgres/*
rm -rf data/mongodb/*
rm -rf data/redis/*

# Reinstall dependencies
python -m venv venv
source venv/bin/activate
pip install -r requirements-dev.txt

npm install

# Restart services
docker-compose up -d

echo "‚úÖ Environment reset complete!"
```

## üìû Contacto y Soporte

### Canales de Soporte

- **üî• Urgente (P0):** Llamar al +52 55 1234 5678
- **üìß Email:** ai@novasolutionsystems.com
- **üí¨ Slack:** #nova-cell-support
- **üìù Tickets:** [JIRA](https://banco.atlassian.net/nova)

### SLA de Respuesta

| Prioridad | Descripci√≥n | Tiempo de Respuesta |
|-----------|-------------|-------------------|
| P0 | Sistema ca√≠do | 15 minutos |
| P1 | Funcionalidad cr√≠tica afectada | 1 hora |
| P2 | Funcionalidad degradada | 4 horas |
| P3 | Pregunta o mejora | 24 horas |

### Informaci√≥n para Reporte de Issues

Cuando reportes un issue, incluye:

```markdown
## Descripci√≥n del Problema
[Descripci√≥n clara del problema]

## Pasos para Reproducir
1. [Paso 1]
2. [Paso 2]
3. [...]

## Comportamiento Esperado
[Qu√© deber√≠a pasar]

## Comportamiento Actual
[Qu√© est√° pasando]

## Ambiente
- OS: [macOS/Linux/Windows]
- Nova-Cell Version: [2.0.3]
- Python Version: [3.11]
- Browser: [si aplica]

## Logs Relevantes
```
[Pegar logs aqu√≠]
```

## Screenshots
[Si aplica]
```

---

*√öltima actualizaci√≥n: Enero 2025 | Versi√≥n 2.0.3*