# üß™ Etapa 2: Experimentar

## üéØ Objetivo de la Etapa

Validar la viabilidad t√©cnica de tu soluci√≥n de IA mediante la construcci√≥n de un Proof of Concept (PoC) o prototipo funcional, demostrando que la tecnolog√≠a puede resolver el problema identificado con los datos disponibles.

### Duraci√≥n T√≠pica
- **6-8 semanas** para PoC completo
- **3-4 semanas** si usas un Green Path
- **2-3 semanas** para spike t√©cnico simple

### Entregables Clave
1. ü§ñ PoC/Prototipo funcional
2. üìä M√©tricas de performance t√©cnica
3. üìà Business case refinado con datos reales
4. üéØ Informe de viabilidad t√©cnica
5. ‚úÖ Go/No-Go decision documentada

## üî¨ Tipos de Experimentaci√≥n

### Elige tu Approach

```mermaid
graph TB
    A[Tipo de Experimentaci√≥n] --> B{Complejidad}
    
    B -->|Baja| C[Spike T√©cnico<br/>2-3 semanas]
    B -->|Media| D[PoC<br/>4-6 semanas]
    B -->|Alta| E[Prototipo<br/>6-8 semanas]
    
    C --> F[Validaci√≥n b√°sica<br/>de concepto]
    D --> G[Validaci√≥n con<br/>datos reales]
    E --> H[Sistema funcional<br/>limitado]
    
    style A fill:#667eea
    style G fill:#764ba2
```

| Tipo | Cu√°ndo Usar | Alcance | Inversi√≥n | Entregables Espec√≠ficos |
|------|------------|---------|-----------|------------------------|
| **Spike T√©cnico** | Validar factibilidad b√°sica | Test de concepto, no producci√≥n | <$100K MXN | ‚Ä¢ Reporte t√©cnico de hallazgos<br/>‚Ä¢ C√≥digo demo en repositorio<br/>‚Ä¢ Recomendaci√≥n Go/No-Go para PoC |
| **PoC** | Demostrar capacidad con datos reales | Funcionalidad core, m√©tricas reales | $100-500K MXN | ‚Ä¢ Modelo funcional (no producci√≥n)<br/>‚Ä¢ Reporte de m√©tricas t√©cnicas<br/>‚Ä¢ Business case refinado<br/>‚Ä¢ Evaluaci√≥n preliminar de riesgos |
| **Prototipo** | Preparar para piloto | Sistema casi completo, UI b√°sica | $500K-1M MXN | ‚Ä¢ Sistema funcional con UI<br/>‚Ä¢ Reporte completo de performance<br/>‚Ä¢ Plan detallado para MVP<br/>‚Ä¢ An√°lisis de integraci√≥n |

## üì• Inputs desde Etapa Explorar

### Entregables Requeridos de la Etapa Anterior
- ‚úÖ **Problema validado** y objetivo de negocio claro
- ‚úÖ **Caso de uso aprobado** con alcance definido
- ‚úÖ **Pre-AISIA Greenlight** (score >40)
- ‚úÖ **Data Access Memo** confirmando viabilidad de datos
- ‚úÖ **Business case preliminar** con ROI proyectado
- ‚úÖ **Presupuesto aprobado** para experimentaci√≥n
- ‚úÖ **Equipo formado** con roles asignados
- ‚úÖ **Compromiso del sponsor** documentado

## üõ†Ô∏è Setup del Experimento

### Paso 1: Ambiente de Experimentaci√≥n

#### Opci√≥n A: Nova-Cell Sandbox
```bash
# Solicitar ambiente en Nova-Cell
nova-cell env create --type=sandbox \
  --project="mi-poc" \
  --duration=8w \
  --resources=medium

# Recursos incluidos:
# - 4 vCPUs, 16GB RAM
# - GPU compartida (opcional)
# - Jupyter Lab preconfigurado
# - Librer√≠as ML/DL est√°ndar
# - Acceso a data lake (read-only)
```

#### Opci√≥n B: Ambiente Cloud
```yaml
cloud_resources:
  provider: Azure/AWS/GCP
  compute:
    type: ml.medium
    gpus: optional
  storage:
    data: 100GB
    models: 50GB
  security:
    network: isolated
    encryption: at-rest
    access: rbac
```

### Paso 2: Acceso a Datos

#### Data Pipeline para PoC

```python
# Template de pipeline seguro para PoC
class PoCDataPipeline:
    def __init__(self, project_id):
        self.project_id = project_id
        self.data_catalog = DataCatalog()
        self.privacy_filter = PrivacyFilter()
    
    def load_data(self, dataset_id):
        # 1. Verificar permisos
        assert self.data_catalog.has_access(dataset_id, self.project_id)
        
        # 2. Cargar datos con sampling
        data = self.data_catalog.load(
            dataset_id,
            sample_size=10000,  # Limitar para PoC
            anonymize=True      # Aplicar anonimizaci√≥n
        )
        
        # 3. Aplicar filtros de privacidad
        data = self.privacy_filter.apply(data)
        
        # 4. Logging para auditor√≠a
        log_data_access(self.project_id, dataset_id)
        
        return data
```

### Paso 3: Metodolog√≠a de Experimentaci√≥n

#### Framework CRISP-DM Adaptado

```mermaid
graph LR
    A[Business<br/>Understanding] --> B[Data<br/>Understanding]
    B --> C[Data<br/>Preparation]
    C --> D[Modeling]
    D --> E[Evaluation]
    E --> F[Business<br/>Validation]
    
    F --> G{Meets<br/>Criteria?}
    G -->|No| C
    G -->|Yes| H[Document<br/>Results]
    
    style A fill:#667eea
    style D fill:#764ba2
    style H fill:#51cf66
```

## üìä M√©tricas de √âxito

### ‚öñÔ∏è M√©tricas Regulatorias y √âticas (Obligatorias)

#### Fairness/Sesgo
| M√©trica | Descripci√≥n | Umbral Aceptable | Requerido por |
|---------|-------------|------------------|---------------|
| **Demographic Parity** | Diferencia en tasa de aprobaci√≥n entre grupos | <5% | CONDUSEF |
| **Equal Opportunity** | Diferencia en tasa de verdaderos positivos | <10% | √âtica AI |
| **Disparate Impact** | Ratio de tasas de selecci√≥n | >0.8 | Regulaci√≥n |
| **Individual Fairness** | Consistencia en decisiones similares | >95% | CNBV |

#### Explainabilidad (XAI)
| Componente | Requisito | Aplicaci√≥n |
|------------|-----------|------------|
| **Feature Importance** | Documentar top 10 features | Todos los modelos |
| **SHAP/LIME valores** | Para decisiones individuales | Modelos Tier 1-2 |
| **Counterfactual Explanations** | "¬øQu√© cambiar√≠a la decisi√≥n?" | Cr√©dito/Riesgo |
| **Natural Language Explanations** | Para usuarios finales | Customer-facing |

#### Robustez y Estabilidad
| Test | M√©trica | Umbral M√≠nimo |
|------|---------|---------------|
| **Data Drift Detection** | PSI (Population Stability Index) | <0.2 |
| **Adversarial Robustness** | Accuracy bajo perturbaciones | >90% del baseline |
| **Stress Testing** | Performance en condiciones extremas | >80% del baseline |
| **Temporal Stability** | Varianza entre per√≠odos | <10% |

### M√©tricas T√©cnicas por Tipo de Modelo

#### Modelos de Clasificaci√≥n
| M√©trica | PoC M√≠nimo | Producci√≥n Target |
|---------|------------|------------------|
| **Accuracy** | >75% | >85% |
| **Precision** | >70% | >80% |
| **Recall** | >70% | >80% |
| **F1-Score** | >70% | >80% |
| **AUC-ROC** | >0.75 | >0.85 |

#### Modelos de Regresi√≥n
| M√©trica | PoC M√≠nimo | Producci√≥n Target |
|---------|------------|------------------|
| **RMSE** | <20% baseline | <10% baseline |
| **MAE** | <15% baseline | <7% baseline |
| **R¬≤** | >0.60 | >0.80 |
| **MAPE** | <20% | <10% |

#### Modelos GenAI/LLM
| M√©trica | PoC M√≠nimo | Producci√≥n Target | M√©todo de Medici√≥n |
|---------|------------|------------------|--------------------|
| **Task-Specific Accuracy** | >70% | >85% | Depende del caso:<br/>‚Ä¢ Q&A: F1/Exact Match<br/>‚Ä¢ Summarization: ROUGE<br/>‚Ä¢ Classification: Accuracy<br/>‚Ä¢ Generation: BLEU/METEOR |
| **Hallucination Rate** | <10% | <5% | Human evaluation + automated checks |
| **Response Time (P95)** | <5s | <2s | Latency monitoring |
| **Safety Score** | >95% | >99% | Toxicity/bias detection |
| **User Satisfaction** | >3.5/5 | >4/5 | Surveys/expert review |
| **Context Relevance** | >80% | >90% | Retrieval accuracy (para RAG) |

### M√©tricas de Negocio vs Baseline

```python
# Framework de evaluaci√≥n de negocio con baseline obligatorio
business_metrics = {
    'baseline_comparison': {
        'current_process': 'Manual/Sistema actual',
        'measurement_period': '3 meses hist√≥ricos',
        'data_source': 'Sistema transaccional'
    },
    'time_saved': {
        'current_process': 120,  # minutos
        'with_ai': 30,           # minutos
        'improvement': '75%'
    },
    'cost_reduction': {
        'current_cost': 1000,     # MXN por transacci√≥n
        'with_ai': 250,
        'savings': '75%'
    },
    'error_reduction': {
        'current_error_rate': 0.05,
        'with_ai': 0.01,
        'improvement': '80%'
    },
    'customer_satisfaction': {
        'current_nps': 30,
        'projected_nps': 45,
        'improvement': '+15 points'
    }
}
```

## üîÑ Puntos de Decisi√≥n Intermedios

### Decision Gates por Tipo de Experimento

```mermaid
graph LR
    A[Spike] --> B{Viable?}
    B -->|S√≠| C[Proceder a PoC]
    B -->|No| D[Terminar/Pivot]
    
    C --> E[PoC] --> F{M√©tricas OK?}
    F -->|S√≠| G[Proceder a Prototipo]
    F -->|No| H[Refinar/Pivot]
    
    G --> I[Prototipo] --> J{Listo para MVP?}
    J -->|S√≠| K[Go to Construir]
    J -->|No| L[Iterate]
    
    style B fill:#ffd43b
    style F fill:#ffd43b
    style J fill:#51cf66
```

## üéØ Experimentos por Caso de Uso

### Green Path: RAG Assistant

```python
# Experimento est√°ndar para RAG
class RAGExperiment:
    def __init__(self):
        self.embeddings_model = "text-embedding-ada-002"
        self.llm_model = "gpt-3.5-turbo"
        self.vector_store = "chromadb"
        
    def run_experiment(self, documents):
        # 1. Preparar documentos
        chunks = self.chunk_documents(documents)
        
        # 2. Crear embeddings
        embeddings = self.create_embeddings(chunks)
        
        # 3. Almacenar en vector DB
        self.store_vectors(embeddings)
        
        # 4. Test queries
        test_results = self.evaluate_retrieval(test_queries)
        
        # 5. M√©tricas
        return {
            'retrieval_accuracy': test_results['accuracy'],
            'response_quality': test_results['quality'],
            'latency': test_results['avg_latency'],
            'cost_per_query': test_results['cost']
        }
```

### Caso Custom: Modelo de Scoring

```python
# Template para experimento de scoring
class ScoringExperiment:
    def __init__(self, model_type='xgboost'):
        self.model_type = model_type
        self.features = load_feature_config()
        
    def experiment_pipeline(self):
        # 1. Feature engineering
        X, y = self.prepare_features()
        
        # 2. Split estratificado
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, stratify=y
        )
        
        # 3. Entrenar m√∫ltiples modelos
        models = {
            'baseline': LogisticRegression(),
            'xgboost': XGBClassifier(),
            'neural': MLPClassifier()
        }
        
        # 4. Comparar performance
        results = {}
        for name, model in models.items():
            model.fit(X_train, y_train)
            y_pred = model.predict(X_test)
            
            results[name] = {
                'auc': roc_auc_score(y_test, y_pred),
                'precision': precision_score(y_test, y_pred),
                'recall': recall_score(y_test, y_pred),
                'f1': f1_score(y_test, y_pred)
            }
        
        return results
```

## üìù Documentaci√≥n del Experimento

### Experiment Card Template

```markdown
# Experiment Card: [Nombre del Experimento]

## Metadata
- **ID**: EXP-2025-001
- **Fecha**: [DD/MM/YYYY]
- **Equipo**: [Nombres]
- **Duraci√≥n**: [X semanas]

## Hip√≥tesis
"Creemos que [soluci√≥n] resolver√° [problema] 
logrando [m√©trica] de [valor]"

## Setup
- **Datos**: [Dataset, volumen, per√≠odo]
- **Modelos**: [Algoritmos probados]
- **Infraestructura**: [Recursos utilizados]
- **Costo**: [Total invertido]

## Resultados
### M√©tricas T√©cnicas
- Accuracy: X%
- Precision: X%
- Recall: X%
- F1: X%

### M√©tricas de Negocio
- Tiempo ahorrado: X%
- Costo reducido: $X
- Errores evitados: X%

## Conclusiones
- ‚úÖ Hip√≥tesis validada/rechazada
- üìä Insights clave
- ‚ö†Ô∏è Riesgos identificados
- üöÄ Recomendaciones

## Artefactos
- [Link a c√≥digo]
- [Link a datos]
- [Link a modelos]
- [Link a presentaci√≥n]
```

## üîÑ Proceso de Iteraci√≥n

### Ciclo de Experimentaci√≥n √Ågil

```mermaid
graph TB
    A[Semana 1-2<br/>Setup] --> B[Semana 3-4<br/>Primera Iteraci√≥n]
    B --> C{Review}
    C -->|Pivot| D[Ajustar Approach]
    C -->|Perseverar| E[Semana 5-6<br/>Refinamiento]
    D --> B
    E --> F[Semana 7-8<br/>Validaci√≥n Final]
    F --> G[Go/No-Go Decision]
    
    style A fill:#667eea
    style C fill:#ffd43b
    style G fill:#51cf66
```

### Sprint Planning

| Sprint | Objetivo | Entregables | Review con |
|--------|----------|-------------|------------|
| **Sprint 0** | Setup y datos | Ambiente listo, datos cargados | Tech Lead |
| **Sprint 1** | Baseline model | Modelo simple funcionando | Data Science Team |
| **Sprint 2** | Mejora modelo | Modelo optimizado | Product Owner |
| **Sprint 3** | Validaci√≥n negocio | M√©tricas de negocio | Stakeholders |
| **Sprint 4** | Documentaci√≥n | Reporte final | Sponsor |

## ‚úÖ Criterios Go/No-Go

### Decision Framework

```python
def evaluate_experiment(results):
    """Eval√∫a el experimento con criterios cuantificables"""
    
    # C√°lculo de m√©tricas compuestas
    roi = calculate_roi(
        benefits=results['cost_savings'] + results['revenue_increase'],
        investment=results['total_investment'],
        period_years=2
    )
    
    data_quality = calculate_data_quality(
        completeness=results['data_completeness'],  # >95%
        accuracy=results['data_accuracy'],          # >90%
        consistency=results['data_consistency'],    # >95%
        timeliness=results['data_freshness']       # <7 d√≠as
    )
    
    risk_score = calculate_risk_score(
        technical_risk=results['technical_complexity'],
        regulatory_risk=results['regulatory_exposure'],
        operational_risk=results['change_management'],
        reputational_risk=results['customer_impact']
    )
    
    # Criterios hard gates (todos deben cumplirse)
    go_criteria = {
        'technical_feasibility': results['primary_metric'] > 0.75,
        'business_value': roi > 1.5,
        'data_availability': data_quality > 0.8,
        'risk_acceptable': risk_score < 0.3,
        'sponsor_support': results['sponsor_signoff'] == True,
        'regulatory_compliance': results['compliance_review_passed'] == True,
        'ethical_ai_review': results['ethics_review_passed'] == True,
        'fairness_check': results['bias_metrics_acceptable'] == True
    }
    
    # Todos los criterios deben cumplirse
    decision = all(go_criteria.values())
    
    if decision:
        return "GO - Proceder a Construir"
    else:
        failed = [k for k, v in go_criteria.items() if not v]
        return f"NO-GO - Revisar: {failed}"
```

### Matriz de Decisi√≥n

| Criterio | Peso | Score (1-5) | Weighted | Threshold | C√≥mo se Calcula |
|----------|------|-------------|----------|-----------|------------------|
| **Viabilidad T√©cnica** | 25% | ? | ? | >3.5 | Promedio de m√©tricas t√©cnicas vs targets |
| **Valor de Negocio** | 20% | ? | ? | >4.0 | ROI + impacto estrat√©gico |
| **Compliance Regulatorio** | 20% | ? | ? | >4.5 | Revisi√≥n legal/compliance (binario 1 o 5) |
| **Calidad de Datos** | 15% | ? | ? | >3.5 | Score compuesto de calidad |
| **Riesgo** | 10% | ? | ? | <3.0 | Inverso del risk score |
| **√âtica y Fairness** | 5% | ? | ? | >4.0 | M√©tricas de sesgo y revisi√≥n √©tica |
| **Adopci√≥n Esperada** | 5% | ? | ? | >3.5 | UAT feedback + change readiness |
| **Total** | 100% | - | ? | >3.5 | Promedio ponderado |

## üö® Alertas y Mitigaciones

### Red Flags Comunes

| Problema | S√≠ntoma | Mitigaci√≥n | Cu√°ndo Escalar |
|----------|---------|------------|----------------|
| **Overfitting** | Train acc >95%, Test <70% | Regularizaci√≥n, m√°s datos | Si persiste 2 sprints |
| **Data Leakage** | M√©tricas irrealmente altas | Auditor√≠a de pipeline | Inmediatamente |
| **Drift** | Performance degrada con tiempo | Monitoreo continuo | >5% degradaci√≥n |
| **Sesgo** | Diferencias por grupo | Fairness constraints | Cualquier discriminaci√≥n |
| **Costo excesivo** | >150% presupuesto | Optimizar recursos | >200% presupuesto |

### Plan B: Pivot Strategies

1. **Si el modelo no converge**: Simplificar problema o cambiar approach
2. **Si los datos son insuficientes**: Synthetic data o transfer learning
3. **Si el ROI no se justifica**: Buscar quick wins parciales
4. **Si hay blockers t√©cnicos**: Evaluar soluciones cloud/vendor

## üîç Validaci√≥n Adicional

### Human-in-the-Loop (HITL) Validation

```python
class HITLValidation:
    def __init__(self, model, human_reviewers):
        self.model = model
        self.reviewers = human_reviewers
        
    def validate_batch(self, test_cases):
        results = []
        for case in test_cases:
            # Predicci√≥n del modelo
            model_output = self.model.predict(case)
            
            # Revisi√≥n humana
            human_feedback = self.get_human_review(
                input=case,
                output=model_output,
                reviewer=self.select_reviewer(case)
            )
            
            results.append({
                'case_id': case.id,
                'model_output': model_output,
                'human_agrees': human_feedback['agrees'],
                'correction': human_feedback.get('correction'),
                'confidence': human_feedback['confidence'],
                'edge_case': human_feedback.get('is_edge_case', False)
            })
            
        return self.calculate_metrics(results)
```

### Early Integration Testing

| Sistema | Test Requerido | Criterio de √âxito |
|---------|---------------|-------------------|
| **APIs Core Banking** | Conectividad y autenticaci√≥n | Latencia <100ms |
| **Data Lake** | Lectura de datos hist√≥ricos | Throughput >1000 rec/s |
| **Sistema de Decisiones** | Formato de output compatible | 100% parseable |
| **Monitoring** | Logs y m√©tricas | Captura completa |
| **Seguridad** | Vulnerability scan | 0 cr√≠ticas, <3 altas |

### User Acceptance Testing (UAT) para Prototipos

```yaml
uat_protocol:
  participants:
    - target_users: 5-10 usuarios finales
    - business_experts: 2-3 domain experts
    - duration: 2-3 d√≠as
  
  evaluation:
    - usability: System Usability Scale (SUS) >68
    - effectiveness: Task completion rate >80%
    - efficiency: Time to complete vs baseline
    - satisfaction: Net Promoter Score (NPS) >30
    - feedback: Qualitative insights for mejoras
```

## üéì Recursos de Soporte

### Expertise Disponible

| Recurso | Disponibilidad | C√≥mo Solicitar | Review Obligatorio |
|---------|---------------|----------------|--------------------|
| **Data Scientists CoE** | 20 hrs/semana | coe-ia@banco.mx | Sprint reviews |
| **ML Engineers** | 10 hrs/semana | Slack #ml-support | Dise√±o t√©cnico |
| **Arquitectos IA** | Consultas ad-hoc | Office hours martes | Arquitectura |
| **Especialistas en √©tica** | Review obligatorio | ethics-ai@banco.mx | ‚úÖ Antes de Go/No-Go |
| **Legal & Compliance** | Review obligatorio | compliance-ai@banco.mx | ‚úÖ Antes de Go/No-Go |
| **Security Team** | Review obligatorio | security-ai@banco.mx | ‚úÖ C√≥digo y datos |

### Herramientas y Templates
- üîß [Nova-Cell Experiment Tracker](../servicios/plataforma/nova-cell-hub.md)
- üìä [Jupyter Notebooks Templates](../templates/experiment-notebooks/)
- üìà [MLflow para tracking](http://mlflow.banco.mx)
- üéØ [A/B Testing Framework](../tools/ab-testing-guide.md)

## üìû Checkpoints y Reviews

### Review Gates Obligatorios

| Semana | Review | Participantes | Decisi√≥n |
|--------|--------|--------------|----------|
| **2** | Technical Feasibility | Tech Lead + Arquitecto | Continue/Adjust |
| **4** | Mid-Point Review | Product Owner + Sponsor | Continue/Pivot |
| **6** | Business Validation | Stakeholders | Refine/Prepare |
| **8** | Go/No-Go | Comit√© Decisi√≥n‚Ä† + Sponsor | Go/No-Go/Iterate |

‚Ä† **Comit√© de Decisi√≥n**: Head of CoE AI, Business Unit Head, Chief Risk Officer, Chief Compliance Officer, Data Protection Officer, Sponsor Ejecutivo

### Preparaci√≥n para Reviews
1. **Deck ejecutivo** (5 slides max)
2. **Demo funcional** (10 min)
3. **M√©tricas dashboard** (live)
4. **Risk assessment** actualizado
5. **Recomendaci√≥n clara** con pr√≥ximos pasos

## üöÄ Transici√≥n a Construir

### Criterios de Salida
- [ ] PoC demuestra viabilidad t√©cnica
- [ ] M√©tricas cumplen umbrales m√≠nimos
- [ ] Business case positivo confirmado
- [ ] Sponsor aprueba continuar
- [ ] Equipo para construcci√≥n identificado
- [ ] Presupuesto para MVP aprobado
- [ ] Riesgos identificados y plan de mitigaci√≥n
- [ ] Documentaci√≥n completa del experimento

### Entregables para Siguiente Etapa
1. **Technical Design Document** (TDD)
2. **Refined Business Case** con datos reales
3. **Risk Assessment** actualizado
4. **Project Plan** para construcci√≥n
5. **Team Charter** con roles definidos

---

**Duraci√≥n estimada**: 6-8 semanas  
**Inversi√≥n t√≠pica**: $300-800K MXN  
**Tasa de √©xito**: 65% avanzan a Construir  
**Soporte CoE**: Full technical support